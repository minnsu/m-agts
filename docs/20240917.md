# 2024-09-17

### 진행 사항
- chat_config 로드 후 채팅 생성하는 코드 구현 (llms.py, load_chat_window.py)
    - 채팅은 QThread를 통해 새로운 스레드에서 실행하도록 구현
    - thread 사용하지 않는 경우, GUI 새로고침이 늦어지는 문제 발생
- stop button을 통해 채팅 중지 가능하도록 구현 - thread terminate하도록
- 엔터키를 통해 입력하도록 구현

### TODO
- 가장 마지막 메시지가 group chat manager가 받게 되면서 callback이 호출되지 않음
    - chat_result에서는 name이 들어있지 않을 수 있어서 누가 보낸지 알 수 없음
    - 대안1: group chat manager 코드만 덮어씌우기(Autogen은 MIT 라이센스이므로)
    - 대안2: 방법 생각해보기
- create_edit_chat_window.py에서 AdvancedLLMConfig(temp, top_p 등) 설정 구현하기
- 채팅 reset, 이어하는 기능 구현 고려해보기
- 설치 파일 및 실행 스크립트(로컬 LLM 서버 키기 등) 작성
- AutoGen에 대해 더욱 알아보기(https://microsoft.github.io/autogen/docs/topics ~)
- [모델 하이퍼파라미터 튜닝 방법 공부하기](https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#metric-to-optimize) -> 비용 절감 + 정확도 상승

